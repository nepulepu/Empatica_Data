{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E4FileFormatter\n",
    "\n",
    "\n",
    "##### **Input:** Unzipped files of raw .csv files downloaded from Empatica. (You only need to specify files)\n",
    "##### **Output:** Properly formatted .csv files compiled from all recordings with correct datatimestamps\n",
    "\n",
    "\n",
    "**Check:** \n",
    "* Time Zone Correction- may need to change this dependent on time zone the data from the watch was uploaded via the E4 Portal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "How my files are formatted: \n",
    "    > Folder for each participant\n",
    "        > Folder named Empatica\n",
    "            > Downloaded all folders (originally zipped) containing csv files from Empatica session\n",
    "            \n",
    "***"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#### First, you need to Unzip files so \n",
    "In Bash/Terminal:\n",
    "cd to directory then:\n",
    "find -name '*.zip' -exec sh -c 'unzip -d \"${1%.*}\" \"$1\"' _ {} \\;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "theid = '1663555632_A001FA_2' #This is the subject ID number (name of file)\n",
    "filesource = './Session/' #This is the source folder that contains all of your participant folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import math\n",
    "import time\n",
    "import collections\n",
    "from collections import OrderedDict\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(file):\n",
    "    dict = OrderedDict()\n",
    "\n",
    "    with open(file, 'rt') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter='\\n')\n",
    "        i =0;\n",
    "        for row in reader:\n",
    "            if(i==0):\n",
    "                timestamp=row[0]\n",
    "                print(timestamp)\n",
    "                timestamp=float(timestamp)+3600*8 #Time Zone Correction - will need to change depending on time zone! (if +8 UTC use \"+\"3600*\"8\")\n",
    "                #print(timestamp)\n",
    "            elif(i==1):\n",
    "                hertz = float(row[0])\n",
    "            elif(i==2):\n",
    "                dict[timestamp]=row[0]\n",
    "            else:\n",
    "                timestamp = timestamp + 1.0/hertz\n",
    "                dict[timestamp]=row[0]\n",
    "            i = i+1.0\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatfile(file, idd, typed):\n",
    "    EDA = {}\n",
    "    EDA = readFile(file = file)\n",
    "    EDA =  {datetime.datetime.utcfromtimestamp(k).strftime('%Y-%m-%d %H:%M:%S.%f'): v for k, v in EDA.items()}\n",
    "    EDAdf = pd.DataFrame.from_dict(EDA, orient='index', columns=['EDA'])\n",
    "    EDAdf['EDA'] = EDAdf['EDA'].astype(float)\n",
    "    \n",
    "    EDAdf['Datetime'] =EDAdf.index\n",
    "    EDAdf['Datetime'] = pd.to_datetime(EDAdf['Datetime'], format='%Y-%m-%dT%H:%M:%S.%f')\n",
    "    EDAdf  = EDAdf.set_index('Datetime')\n",
    "    \n",
    "    out_filename = (filesource + idd + '/output_' + typed + '.csv')\n",
    "    EDAdf.to_csv(out_filename, header=False)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importandexport(idd, typed):\n",
    "    configfiles = glob.glob((filesource + idd + '/' + typed + '.csv'))\n",
    "    print(configfiles)\n",
    "    \n",
    "    [formatfile(file, idd, typed) for file in configfiles]\n",
    "    print(('Completed Import and Export of:' + typed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./Session/1663555632_A001FA_2/EDA.csv']\n",
      "1663555632.000000\n",
      "Done\n",
      "Completed Import and Export of:EDA\n",
      "['./Session/1663555632_A001FA_2/TEMP.csv']\n",
      "1663555632.000000\n",
      "Done\n",
      "Completed Import and Export of:TEMP\n",
      "['./Session/1663555632_A001FA_2/HR.csv']\n",
      "1663555642.000000\n",
      "Done\n",
      "Completed Import and Export of:HR\n",
      "['./Session/1663555632_A001FA_2/BVP.csv']\n",
      "1663555632.00\n",
      "Done\n",
      "Completed Import and Export of:BVP\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listtyped = ['EDA','TEMP', 'HR','BVP'] \n",
    "[importandexport(theid, typed) for typed in listtyped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configfiles = glob.glob((filesource + theid + \"/EDA\" + '.csv'))\n",
    "# print(configfiles)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import & Format ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processAcceleration(x,y,z):\n",
    "    x = float(x)\n",
    "    y = float(y)\n",
    "    z = float(z) \n",
    "    return {'x':x,'y':y,'z':z}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readAccFile(file):\n",
    "    dict = OrderedDict()\n",
    "    \n",
    "    with open(file, 'rt') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',')\n",
    "        i=0;\n",
    "        for row in reader:\n",
    "            if(i == 0):\n",
    "                timestamp = float(row[0])+3600*8 #Time Zone Correction\n",
    "            elif(i == 1):    \n",
    "                hertz=float(row[0])\n",
    "            elif(i == 2):\n",
    "                dict[timestamp]= processAcceleration(row[0],row[1],row[2])\n",
    "            else:\n",
    "                timestamp = timestamp + 1.0/hertz \n",
    "                dict[timestamp] = processAcceleration(row[0],row[1],row[2])\n",
    "            i = i + 1\n",
    "        return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatAccfile(file, idd, typed):\n",
    "    EDA = {}\n",
    "    EDA = readAccFile(file = file)\n",
    "    EDA =  {datetime.datetime.utcfromtimestamp(k).strftime('%Y-%m-%d %H:%M:%S.%f'): v for k, v in EDA.items()}\n",
    "    EDAdf = pd.DataFrame.from_dict(EDA, orient='index', columns=['x', 'y', 'z'])\n",
    "    \n",
    "    EDAdf['x'] = EDAdf['x'].astype(float)\n",
    "    EDAdf['y'] = EDAdf['x'].astype(float)\n",
    "    EDAdf['z'] = EDAdf['x'].astype(float)\n",
    "    \n",
    "    EDAdf['Datetime'] =EDAdf.index\n",
    "    EDAdf['Datetime'] = pd.to_datetime(EDAdf['Datetime'], format='%Y-%m-%dT%H:%M:%S.%f')\n",
    "    EDAdf  = EDAdf.set_index('Datetime')\n",
    "    \n",
    "    out_filename = (filesource + idd + '/output_' + typed + '.csv')\n",
    "    EDAdf.to_csv(out_filename, header=False)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importandexportAcc(idd, typed):\n",
    "    configfiles = glob.glob((filesource + idd + '/' + typed + '.csv'))\n",
    "    print(configfiles)\n",
    "    \n",
    "    [formatAccfile(file, idd, typed) for file in configfiles]\n",
    "    print(('Completed Import and Export of:' + typed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./Session/1663555632_A001FA_2/ACC.csv']\n",
      "Done\n",
      "Completed Import and Export of:ACC\n"
     ]
    }
   ],
   "source": [
    "importandexportAcc(theid, 'ACC') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import & Format IBI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importIBI(file, idd, typed):\n",
    "    IBI = pd.read_csv(file, header=None)\n",
    "    timestampstart = float(IBI[0][0])+3600*8\n",
    "    IBI[0] = (IBI[0][1:len(IBI)]).astype(float)+timestampstart\n",
    "    IBI = IBI.drop([0])\n",
    "    IBI[0] = IBI[0].apply(lambda x: datetime.datetime.utcfromtimestamp(x).strftime('%Y-%m-%d %H:%M:%S.%f'))\n",
    "    IBI  = IBI.set_index(0)\n",
    "    \n",
    "    out_filename = (filesource + idd + '/output_' + typed + '.csv')\n",
    "    IBI.to_csv(out_filename, header=False)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importandexportIBI(idd, typed):\n",
    "    configfiles = glob.glob((filesource + idd + '/' + typed + '.csv'))\n",
    "    print(configfiles)\n",
    "    \n",
    "    [importIBI(file, idd, typed) for file in configfiles]\n",
    "    print(('Completed Import and Export of:' + typed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./Session/1663555632_A001FA_2/IBI.csv']\n"
     ]
    },
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\azrix\\Documents\\GitHub\\Empatica_Data\\E4FileFormatter.ipynb Cell 20'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/azrix/Documents/GitHub/Empatica_Data/E4FileFormatter.ipynb#ch0000018?line=0'>1</a>\u001b[0m importandexportIBI(theid, \u001b[39m'\u001b[39;49m\u001b[39mIBI\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\azrix\\Documents\\GitHub\\Empatica_Data\\E4FileFormatter.ipynb Cell 19'\u001b[0m in \u001b[0;36mimportandexportIBI\u001b[1;34m(idd, typed)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/azrix/Documents/GitHub/Empatica_Data/E4FileFormatter.ipynb#ch0000017?line=1'>2</a>\u001b[0m configfiles \u001b[39m=\u001b[39m glob\u001b[39m.\u001b[39mglob((filesource \u001b[39m+\u001b[39m idd \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m typed \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.csv\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/azrix/Documents/GitHub/Empatica_Data/E4FileFormatter.ipynb#ch0000017?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(configfiles)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/azrix/Documents/GitHub/Empatica_Data/E4FileFormatter.ipynb#ch0000017?line=4'>5</a>\u001b[0m [importIBI(file, idd, typed) \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m configfiles]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/azrix/Documents/GitHub/Empatica_Data/E4FileFormatter.ipynb#ch0000017?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m((\u001b[39m'\u001b[39m\u001b[39mCompleted Import and Export of:\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m typed))\n",
      "\u001b[1;32mc:\\Users\\azrix\\Documents\\GitHub\\Empatica_Data\\E4FileFormatter.ipynb Cell 19'\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/azrix/Documents/GitHub/Empatica_Data/E4FileFormatter.ipynb#ch0000017?line=1'>2</a>\u001b[0m configfiles \u001b[39m=\u001b[39m glob\u001b[39m.\u001b[39mglob((filesource \u001b[39m+\u001b[39m idd \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m typed \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.csv\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/azrix/Documents/GitHub/Empatica_Data/E4FileFormatter.ipynb#ch0000017?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(configfiles)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/azrix/Documents/GitHub/Empatica_Data/E4FileFormatter.ipynb#ch0000017?line=4'>5</a>\u001b[0m [importIBI(file, idd, typed) \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m configfiles]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/azrix/Documents/GitHub/Empatica_Data/E4FileFormatter.ipynb#ch0000017?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m((\u001b[39m'\u001b[39m\u001b[39mCompleted Import and Export of:\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m typed))\n",
      "\u001b[1;32mc:\\Users\\azrix\\Documents\\GitHub\\Empatica_Data\\E4FileFormatter.ipynb Cell 18'\u001b[0m in \u001b[0;36mimportIBI\u001b[1;34m(file, idd, typed)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/azrix/Documents/GitHub/Empatica_Data/E4FileFormatter.ipynb#ch0000016?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimportIBI\u001b[39m(file, idd, typed):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/azrix/Documents/GitHub/Empatica_Data/E4FileFormatter.ipynb#ch0000016?line=1'>2</a>\u001b[0m     IBI \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(file, header\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/azrix/Documents/GitHub/Empatica_Data/E4FileFormatter.ipynb#ch0000016?line=2'>3</a>\u001b[0m     timestampstart \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(IBI[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m])\u001b[39m+\u001b[39m\u001b[39m3600\u001b[39m\u001b[39m*\u001b[39m\u001b[39m8\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/azrix/Documents/GitHub/Empatica_Data/E4FileFormatter.ipynb#ch0000016?line=3'>4</a>\u001b[0m     IBI[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m (IBI[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m:\u001b[39mlen\u001b[39m(IBI)])\u001b[39m.\u001b[39mastype(\u001b[39mfloat\u001b[39m)\u001b[39m+\u001b[39mtimestampstart\n",
      "File \u001b[1;32mc:\\Users\\azrix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\azrix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\azrix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\azrix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\azrix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1235\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1232\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1234\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1235\u001b[0m     \u001b[39mreturn\u001b[39;00m mapping[engine](f, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions)\n\u001b[0;32m   1236\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1237\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\azrix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:75\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     72\u001b[0m     kwds\u001b[39m.\u001b[39mpop(key, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m     74\u001b[0m kwds[\u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m ensure_dtype_objs(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m---> 75\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader \u001b[39m=\u001b[39m parsers\u001b[39m.\u001b[39;49mTextReader(src, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m     77\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munnamed_cols \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39munnamed_cols\n\u001b[0;32m     79\u001b[0m \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\azrix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:551\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mEmptyDataError\u001b[0m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "importandexportIBI(theid, 'IBI') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Resources:\n",
    "* Empatica Timestamp Explanation: https://support.empatica.com/hc/en-us/articles/202800715-Session-start-time-format-and-synchronization-\n",
    "* GitHub withfunctions modified here: https://github.com/Ev4ngelos/EmpaticaBiophysicalSync/blob/master/E4BioSync.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
